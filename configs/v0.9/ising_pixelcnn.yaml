project: Ising_VaTD_v0.9
device: cuda:0
net: model.DiscretePixelCNN
optimizer: torch.optim.AdamW
scheduler: hyperbolic_lr.ExpHyperbolicLR
epochs: 20
batch_size: 512  # Not used for DiscretePixelCNN, but required by RunConfig
seeds: [42]

net_config:
  # Lattice configuration
  size: 16      # 16x16 Ising lattice
  fix_first: 1  # Fix first spin to break symmetry (1 = spin up)

  # Temperature sampling configuration
  batch_size: 256  # Samples per temperature
  num_beta: 8     # Number of temperature samples per batch
  beta_min: 0.2   # 1/T_max (T_max = 5)
  beta_max: 1.0   # 1/T_min (T_min = 1)

  # 3-Phase Curriculum Learning
  # Phase 1: High temp only (disordered) - easier learning
  # Phase 2: Gradual expansion to full range
  # Phase 3: Mixed sampling with Tc focus - reinforce critical region
  # Critical temperature: T_c = 2.269, beta_c = 0.44
  curriculum_enabled: true

  # Phase 1: High temperature only
  phase1_epochs: 50
  phase1_beta_max: 0.35  # T_min = 2.86 (above Tc)

  # Phase 2: Expand to full range
  phase2_epochs: 100  # Duration (not end epoch)

  # Phase 3: Mixed sampling
  # 70% full range + 30% Tc-focused
  tc_focus_ratio: 0.3
  tc_beta_min: 0.38     # T = 2.63 (just above Tc)
  tc_beta_max: 0.52     # T = 1.92 (just below Tc)

  # Model architecture
  kernel_size: 7        # First masked conv kernel size
  hidden_channels: 64   # Hidden channels in residual blocks
  hidden_conv_layers: 5 # Number of residual conv blocks
  hidden_kernel_size: 3 # Kernel size in residual blocks
  hidden_width: 128     # Width of FC layers
  hidden_fc_layers: 2   # Number of FC layers

  # Causal Self-Attention for long-range correlations
  use_attention: true
  attention_heads: 4              # Number of attention heads
  attention_every_n_layers: 2     # Add attention after every N conv layers
  attention_dropout: 0.0          # Dropout in attention

optimizer_config:
  lr: 1.e-3
  weight_decay: 1.e-4

scheduler_config:
  upper_bound: 300
  max_iter: 150
  infimum_lr: 1.e-5

early_stopping_config:
  enabled: false
  patience: 50
  mode: min
  min_delta: 0.0001
