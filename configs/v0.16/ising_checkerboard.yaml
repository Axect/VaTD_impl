# v0.16 Checkerboard PixelCNN
#
# Key innovation: 2-step parallel sampling via checkerboard factorization
# - 128x speedup over sequential PixelCNN (2 steps vs 256 steps)
# - Exploits bipartite structure of square lattice
#
# Factorization:
#   p(x) = p(x_black | prior) * p(x_white | x_black)
#
# Black cells: (i+j) % 2 == 0
# White cells: (i+j) % 2 == 1

project: Ising_VaTD_v0.16
device: cuda:0
net: model_checkerboard.CheckerboardPixelCNN
optimizer: torch.optim.AdamW
scheduler: hyperbolic_lr.ExpHyperbolicLR
epochs: 250
batch_size: 512
seeds: [42]

net_config:
  # Lattice configuration
  size: 16

  # Temperature sampling configuration
  batch_size: 512
  num_beta: 16
  beta_min: 0.2
  beta_max: 1.0

  # Training Mode: Sequential (compatible with existing trainer)
  training_mode: sequential
  accumulation_steps: 64

  # MCMC Guided Training: DISABLED (pure REINFORCE)
  mcmc_enabled: false

  # 2-Phase Curriculum Learning
  curriculum_enabled: true
  phase1_epochs: 100
  phase1_beta_max: 0.35
  phase2_epochs: 150

  # Model architecture (Checkerboard Net)
  hidden_channels: 64
  hidden_conv_layers: 8
  hidden_kernel_size: 3
  hidden_width: 128
  hidden_fc_layers: 2
  dilation_pattern: [1, 2, 4, 8]

  # Iterative refinement (Gibbs-style)
  # num_iterations=1: original 2-step (fastest, may converge slower)
  # num_iterations=2-4: better convergence, still much faster than PixelCNN
  num_iterations: 2

optimizer_config:
  lr: 1.e-3
  weight_decay: 1.e-4

scheduler_config:
  upper_bound: 300
  max_iter: 250
  infimum_lr: 1.e-6

early_stopping_config:
  enabled: false
